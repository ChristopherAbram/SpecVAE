{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare BetaVAE models\n",
    "Compare BetaVAE models w.r.t. the disentanglement scores on HMDB dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from specvae import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_experiment_from_path(filepath):\n",
    "    return pd.read_csv(filepath, index_col=0)\n",
    "\n",
    "def load_experiment(dataset, experiment_name, filename='experiment.csv', base_path=None):\n",
    "    if base_path is None:\n",
    "        filepath = utils.get_project_path() / '.model' / dataset / experiment_name / filename\n",
    "    else:\n",
    "        filepath = base_path / dataset / experiment_name / filename\n",
    "    return load_experiment_from_path(filepath)\n",
    "\n",
    "def load_experiment_sessions(dataset, experiment_name, filenames=['experiment.csv'], base_path=None):\n",
    "    dfs = [load_experiment(dataset, experiment_name, filename, base_path) for filename in filenames]\n",
    "    merged_df = pd.concat(dfs, ignore_index=True)\n",
    "    return merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = [0,1]\n",
    "df = load_experiment_sessions('HMDB', 'betavae_capacity_nextron', \n",
    "    ['experiment01_dms.csv', 'experiment02_dms.csv', 'experiment03_dms.csv', \n",
    "     'experiment04_dms.csv', 'experiment05_dms.csv', 'experiment06_dms.csv'])\n",
    "# df2 = load_experiment_sessions('HMDB', 'betavae_capacity_nextron', \n",
    "#     ['experiment01.csv', 'experiment02.csv', 'experiment03.csv', 'experiment04.csv', \n",
    "#      'experiment05.csv', 'experiment06.csv'])\n",
    "# df = pd.concat([df1, df2], ignore_index=True)\n",
    "df.to_csv(utils.get_project_path() / '.model' / 'betavae_hmdb.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = list(df.columns)\n",
    "params = list(filter(lambda x: x.startswith('param_'), columns))\n",
    "values = list(filter(lambda x: x.startswith('m_'), columns))\n",
    "others = list(filter(lambda x: not x.startswith('m_') and not x.startswith('param_'), columns))\n",
    "# Separate by split:\n",
    "train_values = list(filter(lambda x: x.startswith('m_train_'), columns))\n",
    "valid_values = list(filter(lambda x: x.startswith('m_valid_'), columns))\n",
    "test_values = list(filter(lambda x: x.startswith('m_test_'), columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "def is_symmetric(row):\n",
    "    layer_config = ast.literal_eval(row['layer_config'])\n",
    "    return len(layer_config[0]) == len(layer_config[1])\n",
    "\n",
    "def depth(row):\n",
    "    layer_config = ast.literal_eval(row['layer_config'])\n",
    "    lencoder, ldecoder = len(layer_config[0]) - 2, len(layer_config[1]) - 2\n",
    "    return max(lencoder, ldecoder)\n",
    "\n",
    "df['is_symmetric'] = df.apply(is_symmetric, axis=1)\n",
    "df['depth'] = df.apply(depth, axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add random disentanglement scores for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import itertools as it\n",
    "# pcols =  ['m.train.factor_vae.'       + str(p) for p in it.permutations(indices, len(indices))]\n",
    "# pcols += ['m.valid.beta_vae.'       + str(p) for p in it.permutations(indices, len(indices))]\n",
    "# pcols += ['m.train.factor_vae.'     + str(p) for p in it.permutations(indices, len(indices))]\n",
    "# pcols += ['m.valid.factor_vae.'     + str(p) for p in it.permutations(indices, len(indices))]\n",
    "# pcols += ['m.train.mig.'            + str(p) for p in it.permutations(indices, len(indices))]\n",
    "# pcols += ['m.valid.mig.'            + str(p) for p in it.permutations(indices, len(indices))]\n",
    "\n",
    "# def random_score(row):\n",
    "#     for n in pcols:\n",
    "#         row[n] = np.random.random()\n",
    "#     return row\n",
    "# df = df.apply(random_score, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools as it\n",
    "def prepare_scores(df, indices=[0,1,2]):\n",
    "    def unpivot_by_name(df, score_name):\n",
    "        def split(row):\n",
    "            if 'train' in row['permutation']:\n",
    "                row['permutation'] = row['permutation'].replace('m.train.' + score_name + '.', '')\n",
    "                row['split'] = 'train'\n",
    "            elif 'eval' in row['permutation']:\n",
    "                row['permutation'] = row['permutation'].replace('m.eval.' + score_name + '.', '')\n",
    "                row['split'] = 'valid'\n",
    "            return row\n",
    "        vars = ['m.train.' + score_name + '.' + str(p) for p in it.permutations(indices, len(indices))] + \\\n",
    "                ['m.eval.' + score_name + '.' + str(p) for p in it.permutations(indices, len(indices))]\n",
    "        df1 = df.melt(id_vars=['full_model_name'], value_vars=vars, var_name='permutation', value_name=score_name)\n",
    "        df1 = df1.apply(split, axis=1)\n",
    "        return df1\n",
    "    df1 = unpivot_by_name(df, 'beta_vae')\n",
    "    df2 = unpivot_by_name(df, 'factor_vae')\n",
    "    df3 = unpivot_by_name(df, 'mig')\n",
    "    df_ = pd.merge(df1, df2, on=['full_model_name', 'split', 'permutation'])\n",
    "    df_ = pd.merge(df_, df3, on=['full_model_name', 'split', 'permutation'])\n",
    "    df_ = pd.merge(df_, df, on=['full_model_name'])\n",
    "    return df_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = prepare_scores(df, indices)\n",
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_colwidth\", 200)\n",
    "pd.set_option('display.max_rows', 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best models w.r.t. beta_vae score grouped by beta, n_peaks and permutation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1[['param_beta', 'param_max_num_peaks', 'permutation', 'layer_config', 'full_model_name', \n",
    "    'beta_vae', 'factor_vae', 'mig',\n",
    "    'm_train_cos_sim', 'm_train_eu_dist', 'm_train_per_diff']].loc[\n",
    "    df1.groupby(['param_beta', 'param_max_num_peaks', 'permutation'])['beta_vae'].idxmax()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best models w.r.t. factor_vae score grouped by beta, n_peaks and permutation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1[['param_beta', 'param_max_num_peaks', 'permutation', 'layer_config', 'full_model_name', \n",
    "    'beta_vae', 'factor_vae', 'mig',\n",
    "    'm_train_cos_sim', 'm_train_eu_dist', 'm_train_per_diff']].loc[\n",
    "    df1.groupby(['param_beta', 'param_max_num_peaks', 'permutation'])['factor_vae'].idxmax()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best models w.r.t. MIG score grouped by beta, n_peaks and permutation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1[['param_beta', 'param_max_num_peaks', 'permutation', 'layer_config', 'full_model_name', \n",
    "    'beta_vae', 'factor_vae', 'mig',\n",
    "    'm_train_cos_sim', 'm_train_eu_dist', 'm_train_per_diff']].loc[\n",
    "    df1.groupby(['param_beta', 'param_max_num_peaks', 'permutation'])['mig'].idxmax()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scores for each permutation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(60, 20))\n",
    "sns.boxplot(data=df1, x='param_beta', y='beta_vae', hue='permutation', palette='viridis', ax=axs[0])\n",
    "sns.boxplot(data=df1, x='param_beta', y='factor_vae', hue='permutation', palette='viridis', ax=axs[1])\n",
    "sns.boxplot(data=df1, x='param_beta', y='mig', hue='permutation', palette='viridis', ax=axs[2])\n",
    "axs[0].legend([])\n",
    "axs[1].legend([])\n",
    "plt.legend(loc='upper right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 3, figsize=(30, 20))\n",
    "axs_ = axs.ravel()\n",
    "m = ['BetaVAE', 'FactorVAE', 'MIG']\n",
    "for i, perm in enumerate(it.permutations(indices, len(indices))):\n",
    "    for k in range(3):\n",
    "        axs_[3*i+k].set_title('Metric=' + m[k] + ' | ' + 'permutation='+str(perm)) \n",
    "    sns.violinplot(data=df1[df1['permutation'] == str(perm)], x='param_beta', y='beta_vae', hue='split', ax=axs_[3*i])\n",
    "    sns.violinplot(data=df1[df1['permutation'] == str(perm)], x='param_beta', y='factor_vae', hue='split', ax=axs_[3*i+1])\n",
    "    sns.violinplot(data=df1[df1['permutation'] == str(perm)], x='param_beta', y='mig', hue='split', ax=axs_[3*i+2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 3, figsize=(60, 20))\n",
    "axs_ = axs.ravel()\n",
    "m = ['BetaVAE', 'FactorVAE', 'MIG']\n",
    "for i, perm in enumerate(it.permutations(indices, len(indices))):\n",
    "    for k in range(3):\n",
    "        axs_[3*i+k].set_title('Metric=' + m[k] + ' | ' + 'permutation='+str(perm)) \n",
    "    sns.violinplot(data=df1[df1['permutation'] == str(perm)], x='param_beta', y='beta_vae', hue='param_max_num_peaks', ax=axs_[3*i])\n",
    "    sns.violinplot(data=df1[df1['permutation'] == str(perm)], x='param_beta', y='factor_vae', hue='param_max_num_peaks', ax=axs_[3*i+1])\n",
    "    sns.violinplot(data=df1[df1['permutation'] == str(perm)], x='param_beta', y='mig', hue='param_max_num_peaks', ax=axs_[3*i+2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 3, figsize=(30, 20))\n",
    "axs_ = axs.ravel()\n",
    "m = ['BetaVAE', 'FactorVAE', 'MIG']\n",
    "for i, perm in enumerate(it.permutations(indices, len(indices))):\n",
    "    for k in range(3):\n",
    "        axs_[3*i+k].set_title('Metric=' + m[k] + ' | ' + 'permutation='+str(perm)) \n",
    "    sns.stripplot(data=df1[df1['permutation'] == str(perm)], x='param_beta', y='beta_vae', hue='param_max_num_peaks', ax=axs_[3*i])\n",
    "    sns.stripplot(data=df1[df1['permutation'] == str(perm)], x='param_beta', y='factor_vae', hue='param_max_num_peaks', ax=axs_[3*i+1])\n",
    "    sns.stripplot(data=df1[df1['permutation'] == str(perm)], x='param_beta', y='mig', hue='param_max_num_peaks', ax=axs_[3*i+2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Disentanglement scores rank correlation per permutation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats\n",
    "cmap = sns.diverging_palette(230, 20, as_cmap=True)\n",
    "\n",
    "for perm in it.permutations(indices, len(indices)):\n",
    "    dfp_train = df1[df1['permutation'].isin([str(perm)]) & df1['split'].isin(['train'])][['beta_vae', 'factor_vae', 'mig']]\n",
    "    dfp_valid = df1[df1['permutation'].isin([str(perm)]) & df1['split'].isin(['valid'])][['beta_vae', 'factor_vae', 'mig']]\n",
    "    c1, p1 = scipy.stats.spearmanr(dfp_train)\n",
    "    c2, p2 = scipy.stats.spearmanr(dfp_valid)\n",
    "    \n",
    "    fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "    axs[0].set_title('Train, permutation: ' + str(perm))\n",
    "    axs[1].set_title('Valid, permutation: ' + str(perm))\n",
    "    sns.heatmap(c1, cmap=cmap, square=True, ax=axs[0], vmin=0.0, vmax=1.0, annot=True, linewidths=.5, center=0.5,\n",
    "        xticklabels=['beta_vae', 'factor_vae', 'mig'], yticklabels=['beta_vae', 'factor_vae', 'mig'], cbar=False)\n",
    "    sns.heatmap(c2, cmap=cmap, square=True, ax=axs[1], vmin=0.0, vmax=1.0, annot=True, linewidths=.5, center=0.5,\n",
    "        xticklabels=['beta_vae', 'factor_vae', 'mig'], yticklabels=['beta_vae', 'factor_vae', 'mig'], cbar=False)\n",
    "    fig.colorbar(axs[0].get_children()[0], ax=axs.ravel().tolist(), aspect=10., anchor=(1.6, 0.5), shrink=0.97)\n",
    "    plt.subplots_adjust(wspace=0.1, hspace=0.1)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pairwise scatter plot for different disentanglement metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n_peaks in df1['param_max_num_peaks'].unique():\n",
    "    g = sns.pairplot(df1[df1['param_max_num_peaks'] == n_peaks][['beta_vae', 'factor_vae', 'mig', 'param_beta']], hue='param_beta', height=4)\n",
    "    g.fig.suptitle('n_peaks=' + str(n_peaks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for beta in df1['param_beta'].unique():\n",
    "    g = sns.pairplot(df1[df1['param_beta'] == beta][['beta_vae', 'factor_vae', 'mig', 'param_max_num_peaks']], hue='param_max_num_peaks', height=4)\n",
    "    g.fig.suptitle('beta=' + str(beta))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variance of the disentanglement scores explained by different factors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocess factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign categorical id to continuous variable: param_beta\n",
    "param_beta_unique = df1['param_beta'].unique()\n",
    "param_beta_map = dict(zip(param_beta_unique, range(len(param_beta_unique))))\n",
    "df1['param_beta_id'] = df1.apply(lambda row: param_beta_map[row['param_beta']], axis=1)\n",
    "param_beta_map, df1['param_beta_id'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign categorical id to continuous variable: n_peaks\n",
    "n_peaks_unique = df1['param_max_num_peaks'].unique()\n",
    "n_peaks_map = dict(zip(n_peaks_unique, range(len(n_peaks_unique))))\n",
    "df1['param_max_num_peaks_id'] = df1.apply(lambda row: n_peaks_map[row['param_max_num_peaks']], axis=1)\n",
    "n_peaks_map, df1['param_max_num_peaks_id'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign categorical id to continuous variable: layer_config\n",
    "def reduce_layer_config(row):\n",
    "    layer_config = ast.literal_eval(row['layer_config'])\n",
    "    encoder, decoder = layer_config[0][1:], layer_config[1][:-1]\n",
    "    return str([encoder, decoder])\n",
    "\n",
    "df1['arch'] = df1.apply(reduce_layer_config, axis=1)\n",
    "arch_unique = df1['arch'].unique()\n",
    "arch_map = dict(zip(arch_unique, range(len(arch_unique))))\n",
    "df1['arch_id'] = df1.apply(lambda row: arch_map[row['arch']], axis=1)\n",
    "arch_map, df1['arch_id'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### One hot encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(df, name):\n",
    "    id = df[name].to_numpy()\n",
    "    ids = np.unique(id)\n",
    "    n_values = np.max(ids) + 1\n",
    "    return np.eye(n_values)[id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_beta_ohe = one_hot_encode(df1, 'param_beta_id')\n",
    "n_peaks_ohe = one_hot_encode(df1, 'param_max_num_peaks_id')\n",
    "arch_ohe = one_hot_encode(df1, 'arch_id')\n",
    "param_beta_ohe.shape, n_peaks_ohe.shape, arch_ohe.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "import sklearn.metrics as skm\n",
    "\n",
    "def linear_regression(X, y):\n",
    "    reg = LinearRegression().fit(X, y)\n",
    "    y_pred = reg.predict(X)\n",
    "\n",
    "    mse = skm.mean_squared_error(y, y_pred)\n",
    "    mae = skm.mean_absolute_error(y, y_pred)\n",
    "    me  = skm.max_error(y, y_pred)\n",
    "    evs = skm.explained_variance_score(y, y_pred)\n",
    "    return mse, mae, me, evs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_name = 'beta_vae'\n",
    "X = np.hstack((param_beta_ohe, n_peaks_ohe, arch_ohe))\n",
    "y = df1[score_name].to_numpy()\n",
    "mse, mae, me, evs = linear_regression(X, y)\n",
    "scores.append([mse, mae, me, evs, score_name, 1, 1, 1])\n",
    "\n",
    "X = np.hstack((param_beta_ohe, n_peaks_ohe))\n",
    "y = df1[score_name].to_numpy()\n",
    "mse, mae, me, evs = linear_regression(X, y)\n",
    "scores.append([mse, mae, me, evs, score_name, 1, 1, 0])\n",
    "\n",
    "X = np.hstack((param_beta_ohe, arch_ohe))\n",
    "y = df1[score_name].to_numpy()\n",
    "mse, mae, me, evs = linear_regression(X, y)\n",
    "scores.append([mse, mae, me, evs, score_name, 1, 0, 1])\n",
    "\n",
    "X = np.hstack((n_peaks_ohe, arch_ohe))\n",
    "y = df1[score_name].to_numpy()\n",
    "mse, mae, me, evs = linear_regression(X, y)\n",
    "scores.append([mse, mae, me, evs, score_name, 0, 1, 1])\n",
    "\n",
    "X = param_beta_ohe\n",
    "y = df1[score_name].to_numpy()\n",
    "mse, mae, me, evs = linear_regression(X, y)\n",
    "scores.append([mse, mae, me, evs, score_name, 1, 0, 0])\n",
    "\n",
    "X = n_peaks_ohe\n",
    "y = df1[score_name].to_numpy()\n",
    "mse, mae, me, evs = linear_regression(X, y)\n",
    "scores.append([mse, mae, me, evs, score_name, 0, 1, 0])\n",
    "\n",
    "X = arch_ohe\n",
    "y = df1[score_name].to_numpy()\n",
    "mse, mae, me, evs = linear_regression(X, y)\n",
    "scores.append([mse, mae, me, evs, score_name, 0, 0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_name = 'factor_vae'\n",
    "X = np.hstack((param_beta_ohe, n_peaks_ohe, arch_ohe))\n",
    "y = df1[score_name].to_numpy()\n",
    "mse, mae, me, evs = linear_regression(X, y)\n",
    "scores.append([mse, mae, me, evs, score_name, 1, 1, 1])\n",
    "\n",
    "X = np.hstack((param_beta_ohe, n_peaks_ohe))\n",
    "y = df1[score_name].to_numpy()\n",
    "mse, mae, me, evs = linear_regression(X, y)\n",
    "scores.append([mse, mae, me, evs, score_name, 1, 1, 0])\n",
    "\n",
    "X = np.hstack((param_beta_ohe, arch_ohe))\n",
    "y = df1[score_name].to_numpy()\n",
    "mse, mae, me, evs = linear_regression(X, y)\n",
    "scores.append([mse, mae, me, evs, score_name, 1, 0, 1])\n",
    "\n",
    "X = np.hstack((n_peaks_ohe, arch_ohe))\n",
    "y = df1[score_name].to_numpy()\n",
    "mse, mae, me, evs = linear_regression(X, y)\n",
    "scores.append([mse, mae, me, evs, score_name, 0, 1, 1])\n",
    "\n",
    "X = param_beta_ohe\n",
    "y = df1[score_name].to_numpy()\n",
    "mse, mae, me, evs = linear_regression(X, y)\n",
    "scores.append([mse, mae, me, evs, score_name, 1, 0, 0])\n",
    "\n",
    "X = n_peaks_ohe\n",
    "y = df1[score_name].to_numpy()\n",
    "mse, mae, me, evs = linear_regression(X, y)\n",
    "scores.append([mse, mae, me, evs, score_name, 0, 1, 0])\n",
    "\n",
    "X = arch_ohe\n",
    "y = df1[score_name].to_numpy()\n",
    "mse, mae, me, evs = linear_regression(X, y)\n",
    "scores.append([mse, mae, me, evs, score_name, 0, 0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_name = 'mig'\n",
    "X = np.hstack((param_beta_ohe, n_peaks_ohe, arch_ohe))\n",
    "y = df1[score_name].to_numpy()\n",
    "mse, mae, me, evs = linear_regression(X, y)\n",
    "scores.append([mse, mae, me, evs, score_name, 1, 1, 1])\n",
    "\n",
    "X = np.hstack((param_beta_ohe, n_peaks_ohe))\n",
    "y = df1[score_name].to_numpy()\n",
    "mse, mae, me, evs = linear_regression(X, y)\n",
    "scores.append([mse, mae, me, evs, score_name, 1, 1, 0])\n",
    "\n",
    "X = np.hstack((param_beta_ohe, arch_ohe))\n",
    "y = df1[score_name].to_numpy()\n",
    "mse, mae, me, evs = linear_regression(X, y)\n",
    "scores.append([mse, mae, me, evs, score_name, 1, 0, 1])\n",
    "\n",
    "X = np.hstack((n_peaks_ohe, arch_ohe))\n",
    "y = df1[score_name].to_numpy()\n",
    "mse, mae, me, evs = linear_regression(X, y)\n",
    "scores.append([mse, mae, me, evs, score_name, 0, 1, 1])\n",
    "\n",
    "X = param_beta_ohe\n",
    "y = df1[score_name].to_numpy()\n",
    "mse, mae, me, evs = linear_regression(X, y)\n",
    "scores.append([mse, mae, me, evs, score_name, 1, 0, 0])\n",
    "\n",
    "X = n_peaks_ohe\n",
    "y = df1[score_name].to_numpy()\n",
    "mse, mae, me, evs = linear_regression(X, y)\n",
    "scores.append([mse, mae, me, evs, score_name, 0, 1, 0])\n",
    "\n",
    "X = arch_ohe\n",
    "y = df1[score_name].to_numpy()\n",
    "mse, mae, me, evs = linear_regression(X, y)\n",
    "scores.append([mse, mae, me, evs, score_name, 0, 0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scores = pd.DataFrame(scores, columns=['MSE', 'MAE', 'ME', 'EVS', 'target_value', 'param_beta', 'n_peaks', 'arch'])\n",
    "df_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = df_scores[df_scores['target_value'] == 'beta_vae'].copy()[['param_beta', 'n_peaks', 'arch']]\n",
    "beta_vae_score = df_scores[df_scores['target_value'] == 'beta_vae'].copy()[['MSE', 'MAE', 'ME', 'EVS']]\n",
    "factor_vae_score = df_scores[df_scores['target_value'] == 'factor_vae'].copy()[['MSE', 'MAE', 'ME', 'EVS']]\n",
    "factor_vae_score.index = beta_vae_score.index\n",
    "mig_score = df_scores[df_scores['target_value'] == 'mig'].copy()[['MSE', 'MAE', 'ME', 'EVS']]\n",
    "mig_score.index = factor_vae_score.index\n",
    "df_scores_ = pd.concat([beta_vae_score, factor_vae_score, mig_score], axis=1, ignore_index=True)\n",
    "df_scores_= df_scores_.rename(columns={\n",
    "    0: \"beta_vae_MSE\", 1: \"beta_vae_MAE\", 2: 'beta_vae_ME', 3: 'beta_vae_EVS',\n",
    "    4: \"factor_vae_MSE\", 5: \"factor_vae_MAE\", 6: 'factor_vae_ME', 7: 'factor_vae_EVS',\n",
    "    8: \"mig_MSE\", 9: \"mig_MAE\", 10: 'mig_ME', 11: 'mig_EVS'})\n",
    "\n",
    "# for col in df_scores_.columns:\n",
    "#     df_scores_[col] = np.log10(df_scores_[col] + 1.)\n",
    "df_scores = pd.concat([df_scores_, index], axis=1)\n",
    "df_scores['config'] = 'Config'\n",
    "df_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, axs = plt.subplots(figsize=(15, 15))\n",
    "# axs.scatter(y, y_pred)\n",
    "# axs.plot([np.min(y) - 0.01, np.max(y) + 0.01], [np.min(y_pred) - 0.01, np.max(y_pred) + 0.01], linestyle='dashed', color='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from specvae.visualize import multi_index_heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = multi_index_heatmap(df_scores,\n",
    "    feature_column_name='config', \n",
    "    row_index_columns=['param_beta', 'n_peaks', 'arch'], \n",
    "    sample_columns=['beta_vae_MSE', 'factor_vae_MSE', 'mig_MSE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = multi_index_heatmap(df_scores,\n",
    "    feature_column_name='config', \n",
    "    row_index_columns=['param_beta', 'n_peaks', 'arch'], \n",
    "    sample_columns=['beta_vae_MAE', 'factor_vae_MAE', 'mig_MAE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = multi_index_heatmap(df_scores,\n",
    "    feature_column_name='config', \n",
    "    row_index_columns=['param_beta', 'n_peaks', 'arch'], \n",
    "    sample_columns=['beta_vae_ME', 'factor_vae_ME', 'mig_ME'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = multi_index_heatmap(df_scores,\n",
    "    feature_column_name='config', \n",
    "    row_index_columns=['param_beta', 'n_peaks', 'arch'], \n",
    "    sample_columns=['beta_vae_EVS', 'factor_vae_EVS', 'mig_EVS'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.11 ('specvae')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e9957a820da34b3fdf0ab088e08cc3a6575a1a2738b733f1638214d41ca97147"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
